{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from torch_geometric.loader import DataLoader\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from ConfRankPlus.training.lightning import LightningWrapper\n",
    "from ConfRankPlus.data.dataset import PairDataset, NewMolecularDataset\n",
    "from ConfRankPlus.inference.radius_graph import SmartRadiusGraph\n",
    "from ConfRankPlus.inference.loading import load_ConfRankPlus\n",
    "from ConfRankPlus.model import ConfRankPlus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入文件信息\n",
    "data = {\n",
    "    'confid':构象id，用来区分构象，str,\n",
    "    'ensbid':分子id，一个分子的不同构象要保持ensbid统一，confid不同,\n",
    "    'energy':torch.tensor(energy, dtype=torch.float32),\n",
    "    'total_charge':torch.tensor(charge, dtype=torch.float32),\n",
    "    'z':torch.tensor(symbol_list, dtype=torch.long),\n",
    "    'pos':torch.tensor(positions, dtype=torch.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "dtype = torch.float32\n",
    "compute_forces = False\n",
    "\n",
    "old_model, fidelity_mapping = load_ConfRankPlus(device=device,\n",
    "                                                dtype=dtype,\n",
    "                                                compute_forces=compute_forces)\n",
    "# new\n",
    "model = ConfRankPlus(\n",
    "    hidden_channels=128, \n",
    "    num_blocks=2, \n",
    "    int_emb_size=64,\n",
    "    out_emb_channels=96,\n",
    "    pair_basis_dim=16, \n",
    "    triplet_basis_dim=16, \n",
    "    cutoff=6.5, \n",
    "    cutoff_threebody=4.0, \n",
    "    additive_repulsion_energy=True,\n",
    "    dataset_encoding_dim = 2,\n",
    "    num_dataset_embeddings = 5,\n",
    ")\n",
    "static_dict = old_model.state_dict()\n",
    "model.load_state_dict(static_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_loss_fn = lambda x, y: torch.nn.functional.l1_loss(x, y)\n",
    "lightning_module = LightningWrapper(\n",
    "    model=model,\n",
    "    energy_key='energy',\n",
    "    forces_key=None,\n",
    "    forces_tradeoff=0.0,\n",
    "    atomic_numbers_key=\"z\",\n",
    "    decay_factor=0.5,\n",
    "    decay_patience=3,\n",
    "    energy_loss_fn=energy_loss_fn,\n",
    "    weight_decay=1E-8,\n",
    "    xy_lim=None,\n",
    "    pairwise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('Data/Kwon_2000/FFTsGuess/epoch=0-step=396.ckpt', weights_only=False)\n",
    "lightning_module.load_state_dict(checkpoint[\"state_dict\"], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'Data/Kwon_2000/cfrk_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch_cluster for computing neighborlists.\n",
      "Calculating ensembles ...\n",
      "Calculating ensembles ...\n",
      "Calculating ensembles ...\n"
     ]
    }
   ],
   "source": [
    "train_file = f\"{project_name}/train.pt\"\n",
    "val_file = f\"{project_name}/val.pt\"\n",
    "test_file = f\"{project_name}/test.pt\"\n",
    "radius_graph_transform = SmartRadiusGraph(radius=model.cutoff)\n",
    "trainset = PairDataset(torch.load(train_file, weights_only=False), \n",
    "                       transform=radius_graph_transform)\n",
    "valset = PairDataset(torch.load(val_file, weights_only=False), \n",
    "                     transform=radius_graph_transform)\n",
    "testset = PairDataset(torch.load(test_file, weights_only=False), \n",
    "                      transform=radius_graph_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28404, 3449, 3211)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "num_workers = 1\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "monitor_metric = f\"ptl/val_loss_pairwise\"\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=monitor_metric, \n",
    "    save_top_k=1,\n",
    "    dirpath=f'Data/{project_name}'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=monitor_metric,\n",
    "    min_delta=0.0,\n",
    "    patience=20,\n",
    "    verbose=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "callbacks = [checkpoint_callback, early_stop_callback, lr_monitor]\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=callbacks,\n",
    "    logger=True,\n",
    "    log_every_n_steps=200,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else 'auto',\n",
    "    # accelerator = 'cpu', \n",
    "    devices=[0],\n",
    "    precision=32,\n",
    "    inference_mode=True,\n",
    "    # allow inference mode but only if no force computation is done. For force computation, inference mode must be False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | ConfRankPlus | 471 K  | train\n",
      "-----------------------------------------------\n",
      "470 K     Trainable params\n",
      "624       Non-trainable params\n",
      "471 K     Total params\n",
      "1.886     Total estimated model params size (MB)\n",
      "155       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  69%|██████▉   | 131/190 [00:31<00:14,  4.18it/s, v_num=2, ptl/train_loss_pairwise_step=2.800]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    lightning_module, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = f'Data/{project_name}/test.pt'\n",
    "test_file = f'Data/Kwon_Chiral2/Kwon_Chiral2.pt'\n",
    "temp_testset = NewMolecularDataset('./temp', torch.load(test_file, weights_only=False), \n",
    "                                    transform=radius_graph_transform)\n",
    "temp_test_loader = DataLoader(\n",
    "    temp_testset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_energies = {}\n",
    "with torch.jit.optimized_execution(False):\n",
    "    for each_batch in temp_test_loader:\n",
    "        predict_result = lightning_module.model.forward(each_batch)['energy'].detach().numpy().tolist()\n",
    "        for ensbid, confid, result in zip(each_batch.ensbid, each_batch.confid, predict_result):\n",
    "            final_energies[f\"{ensbid}_{confid}\"] = result\n",
    "        # final_energies += predict_result\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_energies = []\n",
    "with torch.jit.optimized_execution(False):\n",
    "    for each_batch in temp_test_loader:\n",
    "        data = each_batch\n",
    "\n",
    "        model_input_dict = dict(pos=data['pos'],\n",
    "                                z=data['z'].long(),\n",
    "                                edge_index=data['edge_index'],\n",
    "                                total_charge=data['total_charge'],\n",
    "                                batch=data['batch'],\n",
    "                                dataset_idx=torch.full_like(data[\"z\"], dtype=torch.long,\n",
    "                                                            fill_value=0))\n",
    "        predictions = model.forward(model_input_dict)['energy'].detach().numpy().tolist()\n",
    "        final_energies += predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(final_energies, f'Data/{project_name}/Pred.pt')\n",
    "torch.save(final_energies, f'Data/Kwon_Chiral2/Kwon_Chiral2_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final_energies.keys())[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ts1_00000_008_009_0_0': -386062.40625,\n",
       " 'ts2_00000_008_009_0_0': -386063.75,\n",
       " 'ts1_00000_008_009_0_1': -386060.96875,\n",
       " 'ts2_00000_008_009_0_1': -386058.375,\n",
       " 'ts1_00000_008_009_1_0': -386061.96875,\n",
       " 'ts2_00000_008_009_1_0': -386063.5625,\n",
       " 'ts1_00000_008_009_1_1': -386062.5,\n",
       " 'ts2_00000_008_009_1_1': -386061.15625,\n",
       " 'ts2_00000_009_008_0_0': -386060.625,\n",
       " 'ts2_00000_009_008_0_1': -386063.78125,\n",
       " 'ts2_00000_009_008_1_0': -386059.4375,\n",
       " 'ts2_00000_009_008_1_1': -386063.34375,\n",
       " 'ts1_00001_008_009_0_0': -386063.0625,\n",
       " 'ts2_00001_008_009_0_0': -386063.6875,\n",
       " 'ts1_00001_008_009_0_1': -386063.0625,\n",
       " 'ts2_00001_008_009_0_1': -386060.5,\n",
       " 'ts1_00001_008_009_1_0': -386060.15625,\n",
       " 'ts2_00001_008_009_1_0': -386063.75,\n",
       " 'ts1_00001_008_009_1_1': -386061.9375,\n",
       " 'ts2_00001_008_009_1_1': -386059.125,\n",
       " 'ts2_00001_009_008_0_0': -386062.1875,\n",
       " 'ts2_00001_009_008_0_1': -386062.84375,\n",
       " 'ts2_00001_009_008_1_0': -386061.25,\n",
       " 'ts2_00001_009_008_1_1': -386064.0625}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XTB Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xtb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxtb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Molecule, Param, XTB, Constraint\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xtb'"
     ]
    }
   ],
   "source": [
    "from xtb.interface import Molecule, Param, XTB, Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
